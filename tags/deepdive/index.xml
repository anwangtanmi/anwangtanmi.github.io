<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DeepDive on 暗网探秘</title>
    <link>https://anwangtanmi.github.io/tags/deepdive/</link>
    <description>Recent content in DeepDive on 暗网探秘</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 10 Mar 2019 15:10:25 +0800</lastBuildDate>
    <atom:link href="https://anwangtanmi.github.io/tags/deepdive/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>知识图谱一 — 知识图谱架构、DeepDive中文抽取示例</title>
      <link>https://anwangtanmi.github.io/posts/b3ed69224522de9f73c9b0fbbe00026c/</link>
      <pubDate>Sun, 10 Mar 2019 15:10:25 +0800</pubDate>
      <guid>https://anwangtanmi.github.io/posts/b3ed69224522de9f73c9b0fbbe00026c/</guid>
      <description>一. DeepDive DeepDive (http://deepdive.stanford.edu/) 是斯坦福大学开发的信息抽取系统，能处理文本、表格、图表、图片等多种格式的无结构数据，从中抽取结构化的信息。系统集成了文件分析、信息提取、信息整合、概率预测等功能。Deepdive的主要应用是特定领域的信息抽取，系统构建至今，已在交通、考古、地理、医疗等多个领域的项目实践中取得了良好的效果；在开放领域的应用，如TAC-KBP竞赛、维基百科的infobox信息自动增补等项目中也有不错的表现。&#xA;deepdive是由斯坦福大学InfoLab实验室开发的一个开源知识抽取系统，开源地址：https://github.com/HazyResearch/deepdive&#xA;本文用的支持中文的deepdive来自于http://www.openkg.cn/dataset/cn-deepdive，修改了自然语言处理的model包，使它支持中文。&#xA;DeepDive的数据（包括输入，输出，中间media）全都存在关系数据库中，支持数据库类型：postgresql（建议）、mysql、postgresql-xl、greenplum&#xA;DeepDive的系统架构如下图所示，大致分为数据处理、数据标注、学习推理和交互迭代四个流程：&#xA;二. 知识图谱构建流程 知识图谱的架构，包括知识图谱自身的逻辑结构以及构建知识图谱所采用的技术（体系）结构。&#xA;知识图谱的逻辑结构分为两个层次：数据层和模式层。&#xA;在知识图谱的数据层，知识以事实（fact）为单位存储在图数据库。如果以『实体-关系-实体』或者『实体-属性-值』三元组作为事实的基本表达方式，则存储在图数据库中的所有数据将构成庞大的实体关系网络，形成知识的图谱。&#xA;模式层在数据层之上，是知识图谱的核心，在模式层存储的是经过提炼的知识，通常采用本体库来管理知识图谱的模式层，借助本体库对公理、规则和约束条件的支持能力来规范实体、关系以及实体的类型和属性等对象之间的联系。本体库在知识图谱中的地位相当于知识库的模具，拥有本体库的知识库冗余知识较少&#xA;举例：&#xA;模式层：实体-关系-实体；实体-属性-性值&#xA;数据层：比尔盖茨-配偶-梅琳达；比尔盖茨-总裁-微软&#xA;知识图谱有自顶向下和自底向上2种构建方式。所谓自顶向下构建是借助百科类网站等结构化数据源，从高质量数据中提取本体和模式信息，加入到知识库中；所谓自底向上构建，则是借助一定的技术手段，从公开采集的数据中提取出资源模式，选择其中置信度较高的新模式，经人工审核之后，加入到知识库中。 目前知识图谱大多采用自底向上的方式构建，本文也主要介绍自底向上的知识图谱构建技术，按照知识获取的过程分为3个层次：信息抽取、知识融合以及知识加工。&#xA;2.1 知识图谱的构建技术 采用自底向上的方式构建知识图谱的过程是一个迭代更新的过程，每一轮更新包括3个步骤：&#xA;信息抽取，即从各种类型的数据源中提取出实体（概念）、属性以及实体间的相互关系，在此基础上形成本体化的知识表达 知识融合，在获得新知识后，需要对其进行整合，以消除矛盾和歧义，比如某些实体可能有多种表达，某个特定称谓也许对应于多个不同的实体等 知识加工，对于经过融合的新知识，需要经过质量评估之后（部分需要人工参与甄别），才能将合格的部分加入到知识库中，以确保知识库的质量，新增数据之后，可以进行知识推理、拓展现有知识、得到新知识 2.1.1 信息抽取 信息抽取是知识图谱构建的第一步，其中的关键问题是如何从异构数据源中自动抽取信息得到候选知识单元。信息抽取是一种自动化地从半结构化和无结构数据中抽取实体、关系以及实体属性等结构化信息的技术。涉及的关键技术包括：命名实体识别、关系抽取和属性抽取。&#xA;1. 命名实体识别（实体抽取）&#xA;命名实体识别（named entity recognition，NER）也称实体抽取，是指从文本数据集中自动识别出命名实体。实体抽取的质量（准确率和召回率）对后续的知识获取效率和质量影响极大，因此是信息抽取中最为基础和关键的部分。&#xA;2012年Ling等人归纳出112种实体类别，并基于条件随机场CRF进行实体边界识别，最后采用自适应感知机算法实现了对实体的自动分类，取得了不错的效果。&#xA;但是随着互联网中内容的动态变化，采用人工预定义实体分类体系的方式已经很难适应时代的需求，因此提出了面向开放域的实体识别和分类研究。&#xA;在面向开放域的实体识别和分类研究中，不需要（也不可能）为每个领域或者每个实体类别建立单独的语料库作为训练集。因此，该领域面临的主要挑战是如何从给定的少量实体实例中自动发现具有区分力的模型。&#xA;一种思路是根据已知的实体实例进行特征建模，利用该模型处理海量数据集得到新的命名实体列表，然后针对新实体建模，迭代地生成实体标注语料库。&#xA;另一种思路是利用搜索引擎的服务器日志，事先并不给出实体分类等信息，而是基于实体的语义特征从搜索日志中识别出命名实体，然后采用聚类算法对识别出的实体对象进行聚类。&#xA;2. 关系抽取&#xA;文本语料经过实体抽取，得到的是一系列离散的命名实体，为了得到语义信息，还需要从相关的语料中提取出实体之间的关联关系，通过关联关系将实体（概念）联系起来，才能够形成网状的知识结构，研究关系抽取技术的目的，就是解决如何从文本语料中抽取实体间的关系这一基本问题。&#xA;早期的关系抽取研究方法主要是通过人工构造语法和语义规则。随后，出现了大量基于特征向量或者核函数的有监督学习方法，关系抽取的准确性也不断提高。但以上研究成果的共同特点是需要预先定义实体关系类型，如雇佣关系、整体部分关系以及位置关系等。&#xA;与之相对的，Banko等人提出了面向开放域的信息抽取方法框架（open information extraction，OIE），并发布了基于自监督（self-supervised）学习方式的开放信息抽取原型系统（TextRunner），该系统采用少量人工标记数据作为训练集，据此得到一个实体关系分类模型，再依据该模型对开放数据进行分类，依据分类结果训练朴素贝叶斯模型来识别『实体-关系-实体』三元组，经过大规模真实数据测试，取得了显著优于同时期其他方法的结果。&#xA;TextRunner系统中错误的部分主要是一些无意义或者不和逻辑的实体关系三元组，据此引入语法限制条件和字典约束，采用先识别关系指示词，然后再对实体进行识别的策略，有效提高了关系识别准确率。&#xA;研究历程简单总结：&#xA;人工构造语法和语义规则–模式匹配 统计机器学习方法 基于特征向量或核函数的有监督方法 研究重点转向半监督和无监督 开放领域的信息抽取 将面向开放域的信息抽取方法和面向封闭领域的传统方法结合 3. 属性抽取&#xA;属性抽取的目标是从不同信息源中采集特定实体的属性信息。例如针对某个公众人物，可以从网络公开信息中得到其昵称、生日、国籍、教育背景等信息。属性抽取技术能够从多种数据来源中汇集这些信息，实现对实体属性的完整勾画。&#xA;由于可以将实体的属性视为实体与属性值之间的一种名词性关系，因此也可以将属性抽取问题视为关系抽取问题。&#xA;百科类网站提供的半结构化数据是当前实体属性抽取研究的主要数据来源。但是还有大量的实体属性数据隐藏在非结构化的公开数据中。&#xA;一种解决方案是基于百科类网站的半结构化数据，通过自动抽取生成训练语料，用于训练实体属性标注模型，然后将其应用于对非结构化数据的实体属性抽取；&#xA;另一种方案是采用数据挖掘的方法直接从文本中挖掘实体属性与属性值之间的关系模式，据此实现对属性名和属性值在文本中的定位。这种方法的基本假设是属性名和属性值之间在位置上有关联关系，事实上在真实语言环境中，许多实体属性值附近都存在一些用于限制和界定该属性值含义的关键词（属性名），在自然语言处理技术中将这类属性称为有名属性，因此可以利用这些关键字来定位有名属性的属性值。&#xA;2.2 知识融合 通过信息抽取，实现了从非结构化和半结构化数据中获取实体、关系以及实体属性信息的目标，然而，这些结果中可能包含大量的冗余和错误信息，数据之间的关系也是扁平化的，缺乏层次性和逻辑性，因此有必要对其进行清理和整合。知识融合包含2部分内容：实体链接和知识合并。&#xA;2.2.1 实体链接 实体链接（entity linking）是指对于从文本中抽取得到的实体对象，将其链接到知识库中对应的正确实体对象的操作。&#xA;实体链接的基本思想是首先根据给定的实体指称项，从知识库中选出一组候选实体对象，然后通过相似度计算将指称项链接到正确的实体对象。</description>
    </item>
  </channel>
</rss>
